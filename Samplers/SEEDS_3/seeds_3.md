# SEEDS_3

Average score:	13.84	out of 17.25
Total score:	443	out of 552
Average time: 	369.14	s / picture
Average time normalized:	360.73	s / picture *


Like SEEDS_2, the SEEDS_3 sampler is not part of the official Stable Diffusion or Hugging Face Diffusers library. It appears to be an experimental or custom sampler found in advanced tools like ComfyUI, InvokeAI, or internal forks.
Most likely, SEEDS_3 is part of a "multi-seed sampling framework", where the model:
- Generates an image using three seeds in parallel
- Blends or interpolates their latent noise representations
- Produces a hybrid image with properties from all three seed variants


About:
- it is not deterministic
- creative variation is very high
- best used for prompt fusion, seed morphing, ideation
- recommended steps 20â€“30 likely optimal
- CFG range likely works best at 6â€“12


ğ™‹ğ™ğ™˜ğ™©ğ™ªğ™§ğ™š ğ™œğ™šğ™£ğ™šğ™§ğ™–ğ™©ğ™ğ™¤ğ™£ ğ™¨ğ™šğ™©ğ™©ğ™ğ™£ğ™œğ™¨:
- 4 prompts (you can find them here: https://github.com/gctanita/understandingImageGeneration/blob/master/experimentPrompts.md )
- Each prompt was generated 8 times with different seeds (each seed was used across each prompt)
- ğ™ğ™©ğ™šğ™¥ğ™¨: 20
- ğ˜¾ğ™ğ™‚: 3
- ğ™’ğ™ğ™™ğ™©ğ™: 512
- ğ™ƒğ™šğ™ğ™œğ™ğ™©: 512
- ğ™ğ™˜ğ™ğ™šğ™™ğ™ªğ™¡ğ™šğ™§: simple


You can find the raw data here: 
- https://github.com/gctanita/understandingImageGeneration/blob/master/Samplers/SEEDS_3/seeds_3-raw-data.md


Scoring criteria for each series can be found here:
- https://github.com/gctanita/understandingImageGeneration/blob/master/Samplers/scoring_criteria.md


Hardware the setup:
- Graphic Card: NVIDIA GeForce RTX 4060 Ti with 8Gb VRAM 
- CPU: AMD Ryzen 5 5500, 3.60 GHz
- RAM: 32.0 GB, speed of 2400 MT/s 


For each image I gave it a score based on some on a set of subjective criteria designed to assess visual quality and consistency across different samplers. Each anomaly observed in the generated images deducted points from the total score, resulting in a binary scale (1 = acceptable, 0 = flawed). And for each image I recorded how much it took to generate them. Average normalized time means that I have eliminated the biggest 4 times from the series, that contained the loading of the model and / or parsing of the prompt for the first time. 